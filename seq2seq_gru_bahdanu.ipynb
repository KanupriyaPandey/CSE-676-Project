{"cells":[{"cell_type":"code","execution_count":null,"id":"f9f5b1a6","metadata":{"id":"f9f5b1a6"},"outputs":[],"source":["# Imports\n","import pickle\n","import torch\n","import matplotlib.pyplot as plt\n","from torchtext.data.metrics import bleu_score\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"8481c40d","metadata":{"id":"8481c40d"},"outputs":[],"source":["# Helper functions\n","from helpers.preprocessing import preprocess_data, split_data, normalize_data\n","from helpers.model import Encoder, AttentionDecoder\n","from helpers.training import prepare_dataloader, train\n","from helpers.evaluation import generate_translation, evaluate"]},{"cell_type":"code","execution_count":null,"id":"d909c411","metadata":{"id":"d909c411"},"outputs":[],"source":["# Global Variables\n","languages = ['eng', 'fra', 'spa', 'deu', 'por']\n","LANGUAGE1 = languages[0]\n","LANGUAGE2 = languages[2]\n","FILEPATH = f'data/{LANGUAGE1}-{LANGUAGE2}.txt'\n","\n","# Model tuning parameters\n","HIDDEN_SIZE = 128\n","BATCH_SIZE = 32\n","LEARNING_RATE = 0.001\n","DROPOUT = 0.1\n"]},{"cell_type":"markdown","id":"746a7128","metadata":{"id":"746a7128"},"source":["Data preprocessing"]},{"cell_type":"code","execution_count":null,"id":"c229af60","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23231,"status":"ok","timestamp":1701302201051,"user":{"displayName":"Mohammed Yasmeen","userId":"02287253478987425155"},"user_tz":300},"id":"c229af60","outputId":"d693ad80-6eb7-47f9-944a-7cb8420f3cbb"},"outputs":[],"source":["input_language, output_language, line_pairs = preprocess_data(FILEPATH, LANGUAGE1, LANGUAGE2)\n","\n","train_pairs, test_pairs = split_data(line_pairs, test_size=0.2)"]},{"cell_type":"markdown","id":"e39aa0de","metadata":{"id":"e39aa0de"},"source":["Model"]},{"cell_type":"code","execution_count":null,"id":"85b577ad","metadata":{"id":"85b577ad"},"outputs":[],"source":["encoder = Encoder(input_language.n_words, HIDDEN_SIZE, DROPOUT).to(device)\n","decoder = AttentionDecoder(HIDDEN_SIZE, output_language.n_words, DROPOUT).to(device)\n","\n","encoder, decoder"]},{"cell_type":"markdown","id":"5d0508c6","metadata":{"id":"5d0508c6"},"source":["Training"]},{"cell_type":"code","execution_count":null,"id":"c735c095","metadata":{"id":"c735c095"},"outputs":[],"source":["input_language, output_language, train_dataloader = prepare_dataloader(input_language, output_language, train_pairs, BATCH_SIZE)\n","\n","losses_list, accuracies_list = train(train_dataloader, encoder, decoder, epochs=80, learning_rate=LEARNING_RATE, print_every=5, plot_every=5)\n"]},{"cell_type":"code","execution_count":null,"id":"lTc2pKpvdEnx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701302202762,"user":{"displayName":"Mohammed Yasmeen","userId":"02287253478987425155"},"user_tz":300},"id":"lTc2pKpvdEnx","outputId":"bf4c1e2b-bd71-4f52-eb9b-e40a6c80ae4e"},"outputs":[],"source":["print( accuracies_list)\n","print(losses_list)"]},{"cell_type":"markdown","id":"TxP02iIz_YW9","metadata":{"id":"TxP02iIz_YW9"},"source":["Save Model"]},{"cell_type":"code","execution_count":null,"id":"9lrB63zX_XCq","metadata":{"id":"9lrB63zX_XCq"},"outputs":[],"source":["# Save models\n","\n","encoder_filepath = f'saved_models/encoder-{LANGUAGE1}-{LANGUAGE2}-mx15.pth'\n","decoder_filepath = f'saved_models/decoder-{LANGUAGE1}-{LANGUAGE2}-mx15.pth'\n","\n","torch.save(encoder.state_dict(), encoder_filepath)\n","torch.save(decoder.state_dict(), decoder_filepath)"]},{"cell_type":"markdown","id":"82409989","metadata":{"id":"82409989"},"source":["Evaluation"]},{"cell_type":"code","execution_count":null,"id":"xUr_fl9p9t2H","metadata":{"id":"xUr_fl9p9t2H"},"outputs":[],"source":["# Evaluate random training pairs\n","\n","encoder.eval()\n","decoder.eval()\n","\n","references_corpus, candidate_corpus = evaluate(input_language, output_language, encoder, decoder,\n","                                               train_pairs, evaluate_train=True)"]},{"cell_type":"code","execution_count":null,"id":"Dtfs6HwA8sGa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47639,"status":"ok","timestamp":1701302250398,"user":{"displayName":"Mohammed Yasmeen","userId":"02287253478987425155"},"user_tz":300},"id":"Dtfs6HwA8sGa","outputId":"1c376b9b-34ca-4097-bf4c-c3da41d06814"},"outputs":[],"source":["# Evaluate testing pairs\n","\n","candidate_corpus, references_corpus = evaluate(input_language, output_language, encoder, decoder,\n","                                                test_pairs, evaluate_train=False, iterations=len(test_pairs))"]},{"cell_type":"markdown","id":"7a7d8cd0","metadata":{"id":"7a7d8cd0"},"source":["Benchmark"]},{"cell_type":"code","execution_count":null,"id":"mct5Lbik8V9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":767,"status":"ok","timestamp":1701302251152,"user":{"displayName":"Mohammed Yasmeen","userId":"02287253478987425155"},"user_tz":300},"id":"mct5Lbik8V9b","outputId":"cda9ea3e-0d5e-4597-ae0b-39afb4fe6dc7"},"outputs":[],"source":["#GRU with Bahdanau attention\n","bleu = bleu_score(candidate_corpus, references_corpus)\n","\n","bleu_score_percentage = bleu * 100\n","# bleu_score_percentage\n","print(f\"BLEU Score: {bleu_score_percentage:.2f}%\")"]},{"cell_type":"markdown","id":"66f426a9","metadata":{"id":"66f426a9"},"source":["Analysis"]},{"cell_type":"code","execution_count":null,"id":"tMQ70h_gdbva","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"executionInfo":{"elapsed":1328,"status":"ok","timestamp":1701302252477,"user":{"displayName":"Mohammed Yasmeen","userId":"02287253478987425155"},"user_tz":300},"id":"tMQ70h_gdbva","outputId":"b661281b-8db0-4a6f-a04d-beb24030c806"},"outputs":[],"source":["\n","# Plotting loss for the first language pair\n","plt.plot(losses_list, label='Loss')\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training Loss')\n","plt.savefig('training_loss.png')  # Save the loss plot as an image\n","plt.show()\n","plt.close()  # Close the plot to start a new one\n","\n","# Plotting accuracies for the first language pair\n","plt.plot(accuracies_list, label='Accuracy')\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Training Accuracy')\n","plt.savefig('training_accuracy.png')  # Save the accuracy plot as an image\n","plt.show()\n","plt.close()  # Close the plot\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save Lists\n","\n","# Save list as a pickle object\n","\n","loss_filename = f'objects/bahdanau_loss_{LANGUAGE2}_{LANGUAGE1}.pkl'\n","accuracy_filename = f'objects/bahdanau_accuracy_{LANGUAGE2}_{LANGUAGE1}.pkl'\n","\n","with open(loss_filename, 'wb') as file:\n","    pickle.dump(losses_list, file)\n","\n","with open(accuracy_filename, 'wb') as file:\n","    pickle.dump(accuracies_list, file)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
